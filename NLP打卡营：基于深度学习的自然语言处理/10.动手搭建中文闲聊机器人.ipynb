{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 聊天机器人的“前世今生”\n",
    "\n",
    "在 1964 年至 1966 年间，麻省理工学院人工智能实验室的德裔美国计算机科学家约瑟夫·维森鲍姆（Joseph Weizenbaum）开发了历史上第一个聊天机器人 —— Eliza。\n",
    "Eliza 的名字源于爱尔兰剧作家萧伯纳的戏剧作品《卖花女》中的角色，剧中出身贫寒的卖花女 Eliza 通过学习与上流社会沟通的方式，变成大使馆舞会上人人艳羡的“匈牙利王家公主”。作为世界上第一个聊天机器人，Eliza 被其作者赋予了充满戏剧性的内涵。\n",
    "尽管在当时已经存在一些基本的数字语言生成器（可以输出一些连贯文本的程序），但 Eliza 是第一个明确设计用于与人互动的程序。用户可以使用打字机输入人类的自然语言，获得来自机器的响应。正如维森鲍姆解释的那样，Eliza 使“人与计算机之间的对话成为可能 ”。 \n",
    "随着深度学习技术的不断发展，聊天机器人变得越来越智能。我们可以通过机器人来完成一些机械性的问答工作，也可以在闲暇时和智能机器人进行对话，他们的出现让生活变得更丰富多彩。如今通过飞桨与Wechaty的结合就可实现一个简单的聊天机器人。\n",
    "如下图就是基于 PaddleHub + Wechaty 的微信闲聊机器人demo。通过Wechaty获取微信接收的消息，然后使用PaddleHub的plato-mini模型根据对话的上下文生成新的对话文本，最终以微信消息的形式发送，实现闲聊的交互。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/20cf3a3aa31d4a9d88a5080191205cd02081974f1226448aae6cf3ea27f0c7d7)\n",
    "\n",
    "下图是基于 PaddleNLP + Wechaty 的微信情感识别机器人demo。通过Wechaty获取微信接收的消息，然后使用PaddleNLP的TextCNN模型对输入的文本进行情感判断，最终以微信消息的形式返回，实现对文本情感的识别。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8b0589030f884ea096c0042e5f2a2a3a619c6e6e1e3f4f31a887c3082094db4e)\n",
    "\n",
    "\n",
    "感兴趣的同学可参照此demo在自己微信上实现一个情感识别机器人哦～\n",
    "\n",
    "demo链接：[https://github.com/mawenjie8731/paddlenlp-wechaty-demo](https://github.com/mawenjie8731/paddlenlp-wechaty-demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用PaddleNLP生成式API搭建一个聊天机器人\n",
    "\n",
    "近年来，人机对话系统受到了学术界和产业界的广泛关注并取得了不错的发展。开放域对话系统旨在建立一个开放域的多轮对话系统，使得机器可以流畅自然地与人进行语言交互，既可以进行日常问候类的闲聊，又可以完成特定功能，以使得开放域对话系统具有实际应用价值。\n",
    "\n",
    "本实例将重点介绍PaddleNLP内置的**生成式API**的功能和用法，并使用PaddleNLP内置的**plato-mini模型**和配套的**生成式API**实现一个简单的闲聊机器人。\n",
    "\n",
    "### 环境要求\n",
    "\n",
    "* PaddlePaddle\n",
    "\n",
    "   本项目依赖于 PaddlePaddle 2.0 及以上版本，请参考 [安装指南](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html) 进行安装\n",
    "\n",
    "* PaddleNLP \n",
    "\n",
    "   ```shell\n",
    "   pip install --upgrade paddlenlp -i https://pypi.org/simple\n",
    "   ```\n",
    "* sentencepiece \n",
    "\n",
    "   ```shell\n",
    "   pip install --upgrade sentencepiece -i https://pypi.org/simple\n",
    "   ```\n",
    "\n",
    "* Python\n",
    "\n",
    "    Python的版本要求 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "AI Studio平台默认安装了Paddle和PaddleNLP，并定期更新版本。 如需手动更新Paddle，可参考[飞桨安装说明](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/conda/linux-conda.html)，安装相应环境下最新版飞桨框架。\n",
    "\n",
    "使用如下命令确保安装最新版PaddleNLP："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.8)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: pip in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (21.2.4)\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\r\n",
    "!pip install --upgrade sentencepiece "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 生成式API\n",
    "\n",
    "**PaddleNLP针对生成式任务提供了`generate()`函数，内嵌于PaddleNLP所有的生成式模型。支持Greedy Search、Beam Search和Sampling解码策略，用户只需指定解码策略以及相应的参数即可完成预测解码，得到生成的sequence的token ids以及概率得分。**\n",
    "\n",
    "下面给大家展示一个GPT模型使用生成API的例子："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. 加载 `paddlenlp.transformers.GPTChineseTokenizer`用于数据处理\n",
    "\n",
    "文本数据在输入预训练模型之前，需要经过数据处理转化为Feature。这一过程通常包括分词，token to id，add special token等步骤。  \n",
    "\n",
    "**PaddleNLP对于各种预训练模型已经内置了相应的tokenizer**，指定想要使用的模型名字即可加载对应的tokenizer。\n",
    "\n",
    "调用`GPTChineseTokenizer`的`__call__`方法即可将我们说的话转为模型可接受的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-30 23:05:44,716] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/gpt-cpm-small-cn-distill/gpt-cpm-cn-sentencepiece.model\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import GPTChineseTokenizer\r\n",
    "\r\n",
    "# 设置想要使用模型的名称\r\n",
    "model_name = 'gpt-cpm-small-cn-distill'\r\n",
    "tokenizer = GPTChineseTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.708 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[587, 205, 44, 6110, 1215, 8, 9, 2598, 20779, 255, 6629, 8, 12, 3473, 2475, 8, 2316, 11653, 8, 9]\n",
      "Tensor(shape=[1, 20], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[587  , 205  , 44   , 6110 , 1215 , 8    , 9    , 2598 , 20779, 255  , 6629 , 8    , 12   , 3473 , 2475 , 8    , 2316 , 11653, 8    , 9    ]])\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "\r\n",
    "user_input = \"花间一壶酒，独酌无相亲。举杯邀明月，\"\r\n",
    "\r\n",
    "# 将文本转为ids\r\n",
    "input_ids = tokenizer(user_input)['input_ids']\r\n",
    "print(input_ids)\r\n",
    "\r\n",
    "# 将转换好的id转为tensor\r\n",
    "input_ids = paddle.to_tensor(input_ids, dtype='int64').unsqueeze(0)\r\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. 使用PaddleNLP一键加载预训练模型\n",
    "\n",
    "**PaddleNLP提供了GPT,UnifiedTransformer等中文预训练模型，可以通过预训练模型名称完成一键加载。**\n",
    "\n",
    "GPT以Transformer Decoder的编码器为网络基本组件，采用单向注意力机制，适用于长文本生成任务。\n",
    "\n",
    "PaddleNLP目前提供多种中英文GPT预训练模型，我们这次用的是一个小的中文GPT预训练模型。其他预训练模型请参考[模型列表](https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-30 23:05:50,845] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/gpt-cpm-small-cn-distill/gpt-cpm-small-cn-distill.pdparams\n",
      "[2021-08-30 23:05:51,712] [    INFO] - Weights of GPTLMHeadModel not initialized from pretrained model: ['lm_head.decoder_weight']\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import GPTLMHeadModel\r\n",
    "\r\n",
    "# 一键加载中文GPT模型\r\n",
    "model = GPTLMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1, 16], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[39  , 8   , 1181, 211 , 8913, 8   , 12  , 8   , 10  , 8   , 10  , 8   , 10  , 8   , 10  , 8   ]])\n",
      "Tensor(shape=[1, 1], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[-0.33355120]])\n"
     ]
    }
   ],
   "source": [
    "# 调用生成API升成文本\r\n",
    "ids, scores = model.generate(\r\n",
    "                input_ids=input_ids,\r\n",
    "                max_length=16,\r\n",
    "                min_length=1,\r\n",
    "                decode_strategy='greedy_search')\r\n",
    "\r\n",
    "print(ids)\r\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对影成三人。    \n"
     ]
    }
   ],
   "source": [
    "generated_ids = ids[0].numpy().tolist()\r\n",
    "\r\n",
    "# 使用tokenizer将生成的id转为文本\r\n",
    "generated_text = tokenizer.convert_ids_to_string(generated_ids)\r\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "可以看到生成的效果还不错，生成式API的用法也是非常的简便。\n",
    "\n",
    "下面我们来展示一下如何使用UnifiedTransformer模型和生成式API完成闲聊对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. 加载 `paddlenlp.transformers.UnifiedTransformerTokenizer`用于数据处理\n",
    "\n",
    "`UnifiedTransformerTokenizer`的调用方式与GPT相同，但数据处理的API略有不同。\n",
    "\n",
    "调用`UnifiedTransformerTokenizer`的`dialogue_encode`方法即可将我们说的话转为模型可接受的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-30 23:05:52,637] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/plato-mini/plato-mini-vocab.txt\n",
      "[2021-08-30 23:05:52,639] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/plato-mini/plato-mini-spm.model\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import UnifiedTransformerTokenizer\r\n",
    "\r\n",
    "# 设置想要使用模型的名称\r\n",
    "model_name = 'plato-mini'\r\n",
    "tokenizer = UnifiedTransformerTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'position_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "user_input = ['你好啊，你今年多大了']\r\n",
    "\r\n",
    "# 调用dialogue_encode方法生成输入\r\n",
    "encoded_input = tokenizer.dialogue_encode(\r\n",
    "                    user_input,\r\n",
    "                    add_start_token_as_response=True,\r\n",
    "                    return_tensors=True,\r\n",
    "                    is_split_into_words=False)\r\n",
    "\r\n",
    "print(encoded_input.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`dialogue_encode`的详细用法，请参考[dialogue_encode](https://paddlenlp.readthedocs.io/zh/latest/source/paddlenlp.transformers.unified_transformer.tokenizer.html#paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. 使用PaddleNLP一键加载预训练模型\n",
    "\n",
    "与GPT相同，我们可以一键调用UnifiedTransformer预训练模型。\n",
    "\n",
    "[UnifiedTransformer](https://github.com/PaddlePaddle/Knover/tree/luge-dialogue/luge-dialogue)以Transformer的编码器为网络基本组件，采用灵活的注意力机制，十分适合文本生成任务，并在模型输入中加入了标识不同对话技能的special token，使得模型能同时支持闲聊对话、推荐对话和知识对话。\n",
    "\n",
    "PaddleNLP目前为UnifiedTransformer提供了三个中文预训练模型：\n",
    "- `unified_transformer-12L-cn` 该预训练模型是在大规模中文会话数据集上训练得到的\n",
    "- `unified_transformer-12L-cn-luge` 该预训练模型是`unified_transformer-12L-cn`在千言对话数据集上进行微调得到的。\n",
    "- `plato-mini` 该模型使用了十亿级别的中文闲聊对话数据进行预训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-30 23:05:52,717] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/plato-mini/plato-mini.pdparams\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import UnifiedTransformerLMHeadModel\n",
    "\n",
    "model = UnifiedTransformerLMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "下一步我们将处理好的输入传入generate函数，并配置解码策略。\n",
    "\n",
    "这里我们使用的是TopK加sampling的解码策略。即从概率最大的k个结果中按概率进行采样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[20, 18], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[6   , 763 , 1164, 7   , 3   , 67  , 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1585, 7   , 3   , 9   , 94  , 42  , 25375, 7   , 28  , 2   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [912 , 3   , 6   , 763 , 14381, 26028, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1850, 26028, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1850, 26028, 3   , 6   , 87  , 37  , 713 , 3   , 10  , 11  , 25620, 4355, 2   , 0   , 0   , 0   ],\n",
      "        [6   , 28  , 3   , 763 , 1164, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 215 , 449 , 26028, 7   , 3   , 9   , 94  , 16  , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1585, 7   , 3   , 9   , 763 , 42  , 25375, 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1585, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 26028, 7   , 3   , 9   , 94  , 16  , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 215 , 1850, 26203, 26028, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [912 , 28  , 3   , 6   , 763 , 1164, 7   , 3   , 6   , 87  , 10  , 11  , 25354, 1243, 94  , 2   , 0   , 0   ],\n",
      "        [6   , 763 , 1850, 7   , 3   , 215 , 878 , 7   , 3   , 6   , 87  , 30  , 11  , 25408, 769 , 2347, 94  , 2   ],\n",
      "        [6   , 763 , 1164, 7   , 3   , 9   , 94  , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [912 , 28  , 3   , 6   , 763 , 1585, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 26028, 7   , 3   , 9   , 42  , 25375, 7   , 16  , 2   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 28  , 3   , 6   , 763 , 1164, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [912 , 6   , 215 , 2697, 26028, 7   , 9   , 42  , 25375, 7   , 28  , 16  , 2   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1850, 7   , 3   , 9   , 94  , 16  , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ]])\n",
      "Tensor(shape=[20, 1], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[-1.24522018],\n",
      "        [-1.14729643],\n",
      "        [-0.83712775],\n",
      "        [-0.94538420],\n",
      "        [-1.66557407],\n",
      "        [-1.62348187],\n",
      "        [-1.07532704],\n",
      "        [-0.75960904],\n",
      "        [-1.13562894],\n",
      "        [-1.15903497],\n",
      "        [-0.75655520],\n",
      "        [-1.04702473],\n",
      "        [-1.38941920],\n",
      "        [-1.43422914],\n",
      "        [-0.93517542],\n",
      "        [-0.79756647],\n",
      "        [-0.73397017],\n",
      "        [-1.36063826],\n",
      "        [-1.57881129],\n",
      "        [-0.89794350]])\n"
     ]
    }
   ],
   "source": [
    "ids, scores = model.generate(\n",
    "                input_ids=encoded_input['input_ids'],\n",
    "                token_type_ids=encoded_input['token_type_ids'],\n",
    "                position_ids=encoded_input['position_ids'],\n",
    "                attention_mask=encoded_input['attention_mask'],\n",
    "                max_length=64,\n",
    "                min_length=1,\n",
    "                decode_strategy='sampling',\n",
    "                top_k=5,\n",
    "                num_return_sequences=20)\n",
    "\n",
    "print(ids)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我今年23岁了,你多大了?']\n"
     ]
    }
   ],
   "source": [
    "from utils import select_response\r\n",
    "\r\n",
    "# 简单根据概率选取最佳回复\r\n",
    "result = select_response(ids, scores, tokenizer, keep_space=False, num_return_sequences=20)\r\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "关于生成式API更详细的用法，请参考[generate](https://paddlenlp.readthedocs.io/zh/latest/source/paddlenlp.transformers.generation_utils.html#paddlenlp.transformers.generation_utils.GenerationMixin.generate)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 下面我们去终端里试试多轮对话吧！\n",
    "\n",
    "PaddleNLP的example中提供了搭建完整对话系统的代码（[人机交互](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/dialogue/unified_transformer#%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92)）。我们可以去终端里尝试一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以上内容实现基于PaddleNLP，开源不易，希望大家多多支持~ \n",
    "**记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐**\n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a0e8ca7743ea4fe9aa741682a63e767f8c48dc55981f4e44a40e0e00d3ab369e)\n",
    "\n",
    "**更多使用方法可参考PaddleNLP教程**\n",
    "\n",
    "- [使用seq2vec模块进行句子情感分类](https://aistudio.baidu.com/aistudio/projectdetail/1283423)\n",
    "- [使用预训练模型ERNIE优化情感分析](https://aistudio.baidu.com/aistudio/projectdetail/1294333)\n",
    "- [使用BiGRU-CRF模型完成快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1317771)\n",
    "- [使用预训练模型ERNIE优化快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1329361)\n",
    "- [使用Seq2Seq模型完成自动对联](https://aistudio.baidu.com/aistudio/projectdetail/1321118)\n",
    "- [使用预训练模型ERNIE-GEN自动写诗](https://aistudio.baidu.com/aistudio/projectdetail/1339888)\n",
    "- [使用TCN网络完成新冠疫情病例数预测](https://aistudio.baidu.com/aistudio/projectdetail/1290873)\n",
    "- [自定义数据集实现文本多分类任务](https://aistudio.baidu.com/aistudio/projectdetail/1468469)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 加入交流群，一起学习吧\n",
    "\n",
    "现在就加入PaddleNLP的QQ技术交流群，一起交流NLP技术吧！\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/23addd6e565745b9a8c26809fdb2203f79eafcac32174cbfbae98c38ddd7cf1a\" width=\"200\" height=\"250\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
