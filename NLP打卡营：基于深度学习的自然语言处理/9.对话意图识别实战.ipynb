{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 基于预训练模型的槽位填充和意图识别\n",
    "\n",
    "### 意图识别原来如此\n",
    "\n",
    "意图识别是指分析用户的核心需求，输出与查询输入最相关的信息，例如在搜索中要找电影、查快递、市政办公等需求，这些需求在底层的检索策略会有很大的不同，错误的识别几乎可以确定找不到能满足用户需求的内容，导致产生非常差的用户体验；在对话过程中要准确理解对方所想表达的意思，这是具有很大挑战性的任务。\n",
    "例如用户输入查询“仙剑奇侠传”时，我们知道“仙剑奇侠传”既有游戏又有电视剧还有新闻、图片等等，如果我们通过用户意图识别发现该用户是想看“仙剑奇侠传”电视剧的，那我们直接把电视剧作为结果返回给用户，就会节省用户的搜索点击次数，缩短搜索时间，大大提升使用体验。而在对话中如果对方说“我的苹果从不出现卡顿”，那么我们就能通过意图识别判断出此刻的苹果是一个电子设备，而非水果，这样对话就能顺利进行下去。\n",
    "\n",
    "总之，意图识别的准确性能在很大程度上影响着搜索的准确性和对话系统的智能性。\n",
    "\n",
    "本示例将展示如何使用ERNIE预训练模型完成任务型对话中的槽位填充和意图识别任务，这两个任务是一个pipeline型任务对话系统的基石。\n",
    "\n",
    "本示例使用的数据集为CrossWOC中文对话数据集。该数据集包含多个领域，包括景点，餐馆，酒店，交通等。\n",
    "\n",
    "原始数据和数据处理脚本请参见 [CrossWOZ](https://github.com/thu-coai/CrossWOZ)。\n",
    "\n",
    "## 环境要求\n",
    "\n",
    "* PaddlePaddle\n",
    "\n",
    "   本项目依赖于 PaddlePaddle 2.3 及以上版本，请参考 [安装指南](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html) 进行安装\n",
    "\n",
    "* PaddleNLP \n",
    "\n",
    "   ```shell\n",
    "   pip install --upgrade paddlenlp -i https://pypi.org/simple\n",
    "   ```\n",
    "\n",
    "* Python\n",
    "\n",
    "    Python的版本要求 3.7+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "AI Studio平台默认安装了Paddle和PaddleNLP，并定期更新版本。 如需手动更新Paddle，可参考[飞桨安装说明](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/conda/linux-conda.html)，安装相应环境下最新版飞桨框架。\n",
    "\n",
    "使用如下命令确保安装最新版PaddleNLP："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Looking in links: https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
      "Requirement already satisfied: paddlepaddle-gpu==2.3.0.post101 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.3.0.post101)\n",
      "Requirement already satisfied: numpy>=1.13 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==2.3.0.post101) (1.19.5)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==2.3.0.post101) (8.2.0)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==2.3.0.post101) (3.14.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==2.3.0.post101) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==2.3.0.post101) (2.24.0)\n",
      "Requirement already satisfied: astor in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==2.3.0.post101) (0.8.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==2.3.0.post101) (4.4.2)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==2.3.0.post101) (3.3.0)\n",
      "Requirement already satisfied: paddle-bfloat==0.1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==2.3.0.post101) (0.1.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==2.3.0.post101) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==2.3.0.post101) (2019.9.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==2.3.0.post101) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==2.3.0.post101) (1.25.11)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.3.4)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.64.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.1.96)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.3.2)\n",
      "Requirement already satisfied: paddlefsl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.1.0)\n",
      "Requirement already satisfied: paddle2onnx in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.9.8)\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (3.14.0)\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied: dill<0.3.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.3.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (8.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (0.8.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.1.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2.24.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (4.2.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (3.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.19.5)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2022.5.0)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from protobuf<=3.20.0,>=3.1.0->paddlenlp) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp) (4.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (21.4.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->datasets>=2.0.0->paddlenlp) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->datasets>=2.0.0->paddlenlp) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->datasets>=2.0.0->paddlenlp) (2019.3)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install paddlepaddle-gpu==2.3.0.post101 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 示例流程\n",
    "\n",
    "与大多数NLP任务相同，本次示例的展示流程分为以下四步：\n",
    "\n",
    "首先我们从数据准备开始。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/dd30e17318fb48fabb5701fd8a97be8176a1e372dd134cc0826e58cb5401933d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据准备\n",
    "\n",
    "数据准备流程如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/89ba02da6f914297ae2fc438d1c9f773556f226652134fb684ac0186bfa5bb7d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 使用`load_dataset()`自定义数据集\n",
    "\n",
    "使用官方脚本预处理过的数据集已经上传至项目根目录，观察数据集格式后我们可以根据数据格式写出数据文件读取函数，传入`load_dataset()`。即可创建数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你', '好', '，', '麻', '烦', '帮', '我', '推', '荐', '一', '个', '门', '票', '免', '费', '的', '景', '点', '。']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B+Inform+景点+门票', 'I+Inform+景点+门票', 'O', 'O', 'O', 'O']\n",
      "['General+greet+none+none', 'Request+景点+名称+']\n",
      "[]\n",
      "\n",
      "['你', '好', '，', '您', '可', '以', '选', '择', '故', '宫', '，', '八', '达', '岭', '长', '城', '，', '颐', '和', '园', '或', '者', '红', '砖', '美', '术', '馆', '。']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B+Inform+景点+名称', 'I+Inform+景点+名称', 'I+Inform+景点+名称', 'I+Inform+景点+名称', 'I+Inform+景点+名称', 'O']\n",
      "['General+greet+none+none']\n",
      "['你好，麻烦帮我推荐一个门票免费的景点。']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "import json\n",
    "\n",
    "# 读取标签文件并创建label_map\n",
    "def get_label_map(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf8\") as f:\n",
    "        label_list = json.load(f)\n",
    "    \n",
    "    id2label = dict([(idx, label) for idx, label in enumerate(label_list)])\n",
    "    label2id = dict([(label, idx) for idx, label in enumerate(label_list)])\n",
    "    return id2label, label2id\n",
    "\n",
    "id2slot, slot2id = get_label_map('slot_labels.json')\n",
    "id2intent, intent2id = get_label_map('intent_labels.json')\n",
    "\n",
    "intent_weight = [1] * len(intent2id)\n",
    "\n",
    "# 根据本地文件格式定义数据读取生成器\n",
    "def read(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    for entry in data:\n",
    "        yield {\n",
    "            'words': entry[0],\n",
    "            'slots': entry[1],\n",
    "            'intents': entry[2],\n",
    "            'history': entry[4],\n",
    "        }\n",
    "\n",
    "# 将生成器传入load_dataset\n",
    "train_ds = load_dataset(read, filename='train.json', lazy=False)\n",
    "dev_ds = load_dataset(read, filename='test.json', lazy=False)\n",
    "\n",
    "for idx in range(2):\n",
    "    print(train_ds[idx]['words'])\n",
    "    print(train_ds[idx]['slots'])\n",
    "    print(train_ds[idx]['intents'])\n",
    "    print(train_ds[idx]['history'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "关于更多自定义数据集相关内容，请参考[如何自定义数据集](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/dataset_self_defined.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 加载 `paddlenlp.transformers.AutoTokenizer`用于数据处理\n",
    "\n",
    "文本数据在输入 ERNIE 预训练模型之前，需要经过数据处理转化为Feature。这一过程通常包括分词，token to id，add special token等步骤。  \n",
    "\n",
    "**PaddleNLP对于各种预训练模型已经内置了相应的tokenizer**，指定想要使用的模型名字即可加载对应的tokenizer。\n",
    "\n",
    "可以通过调用tokenizer中的方法简单的完成上述数据处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-29 15:11:04,512] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-3.0-medium-zh'.\n",
      "[2022-06-29 15:11:04,515] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/ernie_3.0_medium_zh_vocab.txt\n",
      "[2022-06-29 15:11:04,575] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/tokenizer_config.json\n",
      "[2022-06-29 15:11:04,659] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "import paddlenlp\n",
    "\n",
    "# 设置模型名称\n",
    "MODEL_NAME = 'ernie-3.0-medium-zh'\n",
    "tokenizer = paddlenlp.transformers.AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 调用`map()`方法批量处理数据\n",
    "\n",
    "由于我们传入了`lazy=False`，所以我们使用`load_dataset()`自定义的数据集是`MapDataset`对象。\n",
    "\n",
    "`MapDataset`是`paddle.io.Dataset`的功能增强版本。其内置的`map()`方法适合用来进行批量数据集处理。\n",
    "\n",
    "`map()`方法传入的是一个用于数据处理的function。正好可以与tokenizer相配合。\n",
    "\n",
    "以下是本示例中的用法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "def convert_example(example, tokenizer, use_history=False, no_entity_id=0, max_seq_len=512, mode='train'):\n",
    "    \n",
    "    # 调用tokenizer的数据处理方法把文本转为id\n",
    "    tokenized_input = tokenizer(\n",
    "        example['words'],\n",
    "        is_split_into_words=True,\n",
    "        max_seq_len=max_seq_len)\n",
    "    \n",
    "    # 对槽位标签做截断，保证和input_id等长\n",
    "    slot_labels = example['slots']\n",
    "    if len(tokenized_input['input_ids']) - 2 < len(slot_labels):\n",
    "        slot_labels = slot_labels[:len(tokenized_input['input_ids']) - 2]\n",
    "    \n",
    "    # 根据label_map将槽位标签转为id\n",
    "    tokenized_input['slot_labels'] = [no_entity_id] + [slot2id[label] for label in slot_labels] + [no_entity_id]\n",
    "    \n",
    "    # 由于任务中的意图识别是多标签分类，需要把意图标签转为类似one-hot的格式\n",
    "    intent_labels = np.zeros(len(intent2id), dtype='int64')\n",
    "    for l in example['intents']:\n",
    "        intent_labels[intent2id[l]] = 1\n",
    "        if mode == 'train':\n",
    "            # 统计训练集中每个意图的正样本数\n",
    "            intent_weight[intent2id[l]] += 1\n",
    "    tokenized_input['intent_labels'] = intent_labels\n",
    "    \n",
    "    # 将历史对话用[SEP]拼起来并转成id\n",
    "    if use_history:\n",
    "        tokenized_history = tokenizer(\n",
    "            tokenizer.cls_token+tokenizer.sep_token.join(example['history']),\n",
    "            max_seq_len=max_seq_len)\n",
    "        tokenized_input['history_ids'] = tokenized_history['input_ids']\n",
    "    else:\n",
    "        tokenized_input['history_ids'] = []\n",
    "    return tokenized_input\n",
    "\n",
    "use_history = False\n",
    "max_seq_length = 512\n",
    "\n",
    "train_trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer,\n",
    "        mode='train',\n",
    "        use_history=use_history,\n",
    "        max_seq_len=max_seq_length)\n",
    "\n",
    "dev_trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer,\n",
    "        mode='dev',\n",
    "        use_history=use_history,\n",
    "        max_seq_len=max_seq_length)\n",
    "\n",
    "train_ds.map(train_trans_func, lazy=False)   \n",
    "dev_ds.map(dev_trans_func, lazy=False)\n",
    "\n",
    "# 根据意图的正样本数和总样本数为不同样本赋予不同的权重\n",
    "for intent, intent_id in intent2id.items():\n",
    "    neg_pos = (len(train_ds) - intent_weight[intent_id]) / intent_weight[intent_id]\n",
    "    intent_weight[intent_id] = np.log10(neg_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 226, 170, 4, 1298, 1934, 836, 75, 426, 1645, 7, 27, 232, 1039, 783, 453, 5, 561, 180, 12043, 2]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1, 226, 170, 4, 892, 48, 22, 352, 790, 470, 915, 4, 643, 302, 1560, 84, 257, 4, 3540, 14, 509, 172, 123, 536, 1520, 188, 133, 774, 12043, 2]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in range(2):\r\n",
    "    print(train_ds[idx]['input_ids'])\r\n",
    "    print(train_ds[idx]['token_type_ids'])\r\n",
    "    print(train_ds[idx]['slot_labels'])\r\n",
    "    print(train_ds[idx]['intent_labels'])\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "从以上结果可以看出，数据集中的example已经被转换成了模型可以接收的feature，包括input_ids、token_type_ids、slot_labels和intent_labels。\n",
    "其中：\n",
    "\n",
    "* `input_ids`: 表示输入文本的token ID。\n",
    "* `token_type_ids`: 表示token所属的句子（Transformer类预训练模型支持单句以及句对输入）。\n",
    "* `slot_labels`: 槽位标签，其长度与输入文本相同。\n",
    "* `intent_labels`: 意图标签，是一个长度等于总便签数的列表，标签对应位置为1，其余为0.\n",
    "\n",
    "更多有关数据处理的内容，请参考[数据处理](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Batchify和数据读入\n",
    "\n",
    "使用`paddle.io.BatchSampler`和`paddlenlp.data`中提供的方法把数据组成batch。\n",
    "\n",
    "然后使用`paddle.io.DataLoader`接口多线程异步加载数据。\n",
    "\n",
    "`batchify_fn`详解：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/30e43d4659384375a2a2c1b890ca5a995c4324d7168e49cebf1d2a1e99161f7d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from paddlenlp.data import Stack, Dict, Pad\r\n",
    "from paddlenlp.data import DataCollatorWithPadding\r\n",
    "\r\n",
    "batch_size = 20\r\n",
    "\r\n",
    "# 初始化BatchSampler\r\n",
    "train_batch_sampler = paddle.io.BatchSampler(\r\n",
    "    train_ds, batch_size=batch_size, shuffle=True)\r\n",
    "\r\n",
    "dev_batch_sampler = paddle.io.BatchSampler(\r\n",
    "    dev_ds, batch_size=batch_size, shuffle=False)\r\n",
    "\r\n",
    "# 定义batchify_fn\r\n",
    "batchify_fn = lambda samples, fn=Dict({\r\n",
    "    \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id), \r\n",
    "    \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\r\n",
    "    \"slot_labels\": Pad(axis=0, pad_val=0, dtype=\"int64\"),\r\n",
    "    \"intent_labels\": Stack(dtype=\"float32\"),\r\n",
    "    \"history_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id)\r\n",
    "}): fn(samples)\r\n",
    "\r\n",
    "# batchify_fn = DataCollatorWithPadding(tokenizer)\r\n",
    "\r\n",
    "# 初始化DataLoader\r\n",
    "train_data_loader = paddle.io.DataLoader(\r\n",
    "    dataset=train_ds,\r\n",
    "    batch_sampler=train_batch_sampler,\r\n",
    "    collate_fn=batchify_fn,\r\n",
    "    return_list=True)\r\n",
    "\r\n",
    "dev_data_loader = paddle.io.DataLoader(\r\n",
    "    dataset=dev_ds,\r\n",
    "    batch_sampler=dev_batch_sampler,\r\n",
    "    collate_fn=batchify_fn,\r\n",
    "    return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "更多PaddleNLP内置的batchify相关API，请参考[collate](https://paddlenlp.readthedocs.io/zh/latest/source/paddlenlp.data.collate.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "到这里数据集准备就全部完成了，下一步我们需要组网并设计loss function。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fdcb44a00ede4ce08ae2652931556fb58cc903f686bf491792489353d2800e7d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型结构\n",
    "\n",
    "## 使用PaddleNLP一键加载预训练模型\n",
    "\n",
    "以下项目以ERNIE为例，介绍如何将预训练模型多任务学习同时完成意图识别和槽位填充任务。\n",
    "\n",
    "本例中的意图识别和槽位填充本质上是一个句子分类任务和一个序列标注任务。将两者的loss结合即可实现多任务学习。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d9ff881921d74602acb6eb27c8523cb50285f07a7beb4a3cbfa1edbd9b3f9c5c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-29 15:11:15,483] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/ernie_3.0_medium_zh.pdparams\n",
      "W0629 15:11:15.487289  4452 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0629 15:11:15.491648  4452 gpu_context.cc:306] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "from src.models import JointErnie\r\n",
    "\r\n",
    "model = JointErnie.from_pretrained(MODEL_NAME, \r\n",
    "                                   intent_dim=len(intent2id), \r\n",
    "                                   slot_dim=len(slot2id), \r\n",
    "                                   dropout=0.1, \r\n",
    "                                   use_history=use_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 设计loss function\n",
    "\n",
    "JointErnie模型会取出ErnieModel的sequence_output接入一个输出维度为槽位类别数的线性层得到slot_logits，并将pooled_output接入一个输出维度为意图类别数的线性层得到intent_logit.\n",
    "\n",
    "所以本示例中的loss由slot_loss和intent_loss两部分组成，我们需要自己定义loss function。\n",
    "\n",
    "槽位填充相当于在每个token的位置进行一次多分类任务，意图识别相当于对整句话做一个多标签分类任务。所以设计的loss function如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NLULoss(paddle.nn.Layer):\r\n",
    "    def __init__(self, pos_weight):\r\n",
    "        super(NLULoss, self).__init__()\r\n",
    "\r\n",
    "        self.intent_loss_fn = paddle.nn.BCEWithLogitsLoss(pos_weight=paddle.to_tensor(pos_weight))\r\n",
    "        self.slot_loss_fct = paddle.nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "    def forward(self, logits, slot_labels, intent_labels):\r\n",
    "        slot_logits, intent_logits = logits\r\n",
    "\r\n",
    "        slot_loss = self.slot_loss_fct(slot_logits, slot_labels)\r\n",
    "        intent_loss = self.intent_loss_fn(intent_logits, intent_labels)\r\n",
    "\r\n",
    "        return slot_loss + intent_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "选择网络结构后，我们需要设置Fine-Tune优化策略。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7eca6595f338409498149cb586c077ba4933739810cf436080a2292be7e0a92d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 设置Fine-Tune优化策略\n",
    "适用于ERNIE/BERT这类Transformer模型的学习率为warmup的动态学习率。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/2bc624280a614a80b5449773192be460f195b13af89e4e5cbaf62bf6ac16de2c\" width=\"40%\" height=\"30%\"/> <br />\n",
    "</p>\n",
    "<br><center>图3：动态学习率示意图</center></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练过程中的最大学习率\r\n",
    "learning_rate = 3e-5 \r\n",
    "\r\n",
    "# 训练轮次\r\n",
    "epochs = 1\r\n",
    "\r\n",
    "# 学习率预热比例\r\n",
    "warmup_proportion = 0.0\r\n",
    "\r\n",
    "# 权重衰减系数，类似模型正则项策略，避免模型过拟合\r\n",
    "weight_decay = 0.0\r\n",
    "\r\n",
    "max_grad_norm = 1.0\r\n",
    "\r\n",
    "num_training_steps = len(train_data_loader) * epochs\r\n",
    "\r\n",
    "# 学习率衰减策略\r\n",
    "lr_scheduler = paddlenlp.transformers.LinearDecayWithWarmup(learning_rate, num_training_steps,\r\n",
    "                                    warmup_proportion)\r\n",
    "\r\n",
    "decay_params = [\r\n",
    "    p.name for n, p in model.named_parameters()\r\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\r\n",
    "]\r\n",
    "\r\n",
    "# 定义优化器\r\n",
    "optimizer = paddle.optimizer.AdamW(\r\n",
    "    learning_rate=lr_scheduler,\r\n",
    "    parameters=model.parameters(),\r\n",
    "    weight_decay=weight_decay,\r\n",
    "    apply_decay_param_fun=lambda x: x in decay_params,\r\n",
    "    grad_clip=paddle.nn.ClipGradByGlobalNorm(max_grad_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "现在万事俱备，我们可以开始训练模型。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6975542d488f4f75b385fe75d574a3aaa8e208f5e99f4acd8a8e8aea3b85c058)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练与评估\n",
    "\n",
    "模型训练的过程通常有以下步骤：\n",
    "\n",
    "1. 从dataloader中取出一个batch data\n",
    "2. 将batch data喂给model，做前向计算\n",
    "3. 将前向计算结果传给损失函数，计算loss。\n",
    "4. loss反向回传，更新梯度。重复以上步骤。\n",
    "\n",
    "每训练一个epoch后，程序对调用`evaluation()`方法分别计算两个任务的F1 score。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1000, epoch: 1, batch: 1000, loss: 0.17512\n",
      "global step 2000, epoch: 1, batch: 2000, loss: 0.09479\n",
      "global step 3000, epoch: 1, batch: 3000, loss: 0.02178\n",
      "global step 4000, epoch: 1, batch: 4000, loss: 0.07578\n",
      "\n",
      "Eval begin...\n",
      "Total samples: 8476\n",
      "Slot F1: 0.9397\n",
      "Intent F1: 0.6043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils import evaluation\r\n",
    "\r\n",
    "criterion = NLULoss(intent_weight)\r\n",
    "global_step = 0\r\n",
    "\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\r\n",
    "        global_step += 1\r\n",
    "        input_ids, token_type_ids, slot_labels, intent_labels, history_ids = batch\r\n",
    "        logits = model(input_ids, token_type_ids, history_ids=history_ids)\r\n",
    "        loss = criterion(logits, slot_labels, intent_labels)\r\n",
    "\r\n",
    "        if global_step % 1000 == 0 :\r\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f\" % (global_step, epoch, step, loss))\r\n",
    "\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        lr_scheduler.step()\r\n",
    "        optimizer.clear_grad()\r\n",
    "    \r\n",
    "    print('\\nEval begin...')\r\n",
    "    evaluation(model, dev_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# convert to static graph with specific input description\n",
    "model = paddle.jit.to_static(\n",
    "    model,\n",
    "    input_spec=[\n",
    "        paddle.static.InputSpec(\n",
    "            shape=[None, None], dtype=\"int64\"),  # input_ids\n",
    "        paddle.static.InputSpec(\n",
    "            shape=[None, None], dtype=\"int64\")  # segment_ids\n",
    "    ])\n",
    "# save converted static graph model\n",
    "paddle.jit.save(model, \"infer_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35m--- Running analysis [ir_graph_build_pass]\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Running analysis [ir_graph_clean_pass]\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Running analysis [ir_analysis_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [simplify_with_basic_ops_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [layer_norm_fuse_pass]\u001b[0m\n",
      "\u001b[37m---    Fused 0 subgraphs into layer_norm op.\u001b[0m\n",
      "\u001b[32m--- Running IR pass [attention_lstm_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [seqconv_eltadd_relu_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [seqpool_cvm_concat_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [mul_lstm_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [fc_gru_fuse_pass]\u001b[0m\n",
      "\u001b[37m---    fused 0 pairs of fc gru patterns\u001b[0m\n",
      "\u001b[32m--- Running IR pass [mul_gru_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [seq_concat_fc_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [gpu_cpu_squeeze2_matmul_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [gpu_cpu_reshape2_matmul_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [gpu_cpu_flatten2_matmul_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [matmul_v2_scale_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [gpu_cpu_map_matmul_v2_to_mul_pass]\u001b[0m\n",
      "I0629 15:14:50.948932  4452 fuse_pass_base.cc:57] ---  detected 41 subgraphs\n",
      "\u001b[32m--- Running IR pass [gpu_cpu_map_matmul_v2_to_matmul_pass]\u001b[0m\n",
      "I0629 15:14:50.950546  4452 fuse_pass_base.cc:57] ---  detected 12 subgraphs\n",
      "\u001b[32m--- Running IR pass [matmul_scale_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [gpu_cpu_map_matmul_to_mul_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [fc_fuse_pass]\u001b[0m\n",
      "I0629 15:14:51.109480  4452 fuse_pass_base.cc:57] ---  detected 41 subgraphs\n",
      "\u001b[32m--- Running IR pass [repeated_fc_relu_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [squared_mat_sub_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [conv_bn_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [conv_transpose_bn_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [conv_transpose_eltwiseadd_bn_fuse_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [is_test_pass]\u001b[0m\n",
      "\u001b[32m--- Running IR pass [runtime_context_cache_pass]\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Running analysis [ir_params_sync_among_devices_pass]\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Running analysis [adjust_cudnn_workspace_size_pass]\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Running analysis [inference_op_replace_pass]\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Running analysis [ir_graph_to_program_pass]\u001b[0m\n",
      "I0629 15:14:51.213642  4452 analysis_predictor.cc:1007] ======= optimize end =======\n",
      "I0629 15:14:51.222798  4452 naive_executor.cc:102] ---  skip [feed], feed -> token_type_ids\n",
      "I0629 15:14:51.222833  4452 naive_executor.cc:102] ---  skip [feed], feed -> words_ids\n",
      "I0629 15:14:51.225849  4452 naive_executor.cc:102] ---  skip [linear_80.tmp_1], fetch -> fetch\n",
      "I0629 15:14:51.225895  4452 naive_executor.cc:102] ---  skip [linear_81.tmp_1], fetch -> fetch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[ 6.7814775, -3.1593466, -4.1632333, ..., -3.7419374,\n",
      "         -4.0669   , -4.0492043],\n",
      "        [11.554589 , -4.407591 , -4.827274 , ..., -4.422597 ,\n",
      "         -4.71447  , -5.1776814],\n",
      "        [11.688357 , -4.48243  , -4.6533675, ..., -4.3366413,\n",
      "         -4.8391576, -5.326421 ],\n",
      "        ...,\n",
      "        [13.176665 , -4.1729155, -4.728089 , ..., -4.333272 ,\n",
      "         -4.9682946, -5.3904204],\n",
      "        [13.158845 , -4.175857 , -4.732219 , ..., -4.3447914,\n",
      "         -4.961181 , -5.3807683],\n",
      "        [13.149474 , -4.165904 , -4.7227573, ..., -4.349148 ,\n",
      "         -4.969923 , -5.3987556]],\n",
      "\n",
      "       [[11.390071 , -4.130967 , -3.9426858, ..., -3.426007 ,\n",
      "         -5.054478 , -5.846622 ],\n",
      "        [11.302519 , -3.725232 , -4.90538  , ..., -4.3901167,\n",
      "         -4.0434284, -4.9326787],\n",
      "        [11.920896 , -4.1674213, -4.367908 , ..., -4.548027 ,\n",
      "         -4.3104568, -5.063277 ],\n",
      "        ...,\n",
      "        [13.779258 , -4.145918 , -4.428103 , ..., -4.0718894,\n",
      "         -4.791253 , -5.410724 ],\n",
      "        [13.770816 , -4.140418 , -4.4266276, ..., -4.071643 ,\n",
      "         -4.7830377, -5.3985143],\n",
      "        [13.779096 , -4.1328306, -4.4179735, ..., -4.0831933,\n",
      "         -4.791615 , -5.4085517]],\n",
      "\n",
      "       [[ 7.456374 , -2.5692027, -4.24109  , ..., -3.810097 ,\n",
      "         -3.3252873, -4.0920987],\n",
      "        [ 8.574683 , -2.2495499, -4.775242 , ..., -4.3209004,\n",
      "         -3.6838706, -4.957653 ],\n",
      "        [ 8.927279 , -3.9099152, -3.0694826, ..., -3.6171744,\n",
      "         -4.7853646, -5.089115 ],\n",
      "        ...,\n",
      "        [13.01001  , -3.5385768, -4.4491134, ..., -4.2443357,\n",
      "         -4.598784 , -5.3697066],\n",
      "        [12.998647 , -3.5454564, -4.4575524, ..., -4.237321 ,\n",
      "         -4.6142797, -5.3851476],\n",
      "        [12.970467 , -3.5336912, -4.4596734, ..., -4.2461004,\n",
      "         -4.6133094, -5.3774924]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[10.560348 , -3.765053 , -3.6276329, ..., -1.9620574,\n",
      "         -4.5778565, -5.420154 ],\n",
      "        [10.790459 , -2.9837272, -4.1767244, ..., -3.850499 ,\n",
      "         -3.7639039, -5.470011 ],\n",
      "        [11.995274 , -3.8022048, -2.9080052, ..., -3.2904434,\n",
      "         -4.5493007, -5.2190175],\n",
      "        ...,\n",
      "        [13.353181 , -3.8353279, -4.085818 , ..., -3.3101988,\n",
      "         -4.67991  , -5.3841143],\n",
      "        [13.35966  , -3.8365638, -4.078427 , ..., -3.313433 ,\n",
      "         -4.686747 , -5.3946424],\n",
      "        [13.341045 , -3.8436782, -4.0968795, ..., -3.314594 ,\n",
      "         -4.680817 , -5.384107 ]],\n",
      "\n",
      "       [[ 8.224532 , -3.576959 , -4.44025  , ..., -3.8914473,\n",
      "         -3.3392422, -3.2988927],\n",
      "        [12.265505 , -3.804784 , -4.2402215, ..., -4.5345654,\n",
      "         -4.5437865, -5.1761727],\n",
      "        [12.476783 , -3.9929006, -3.3433301, ..., -4.0739303,\n",
      "         -4.920037 , -5.2187667],\n",
      "        ...,\n",
      "        [13.492063 , -4.144082 , -4.431912 , ..., -4.124772 ,\n",
      "         -4.6841397, -5.151851 ],\n",
      "        [13.48388  , -4.1280503, -4.42345  , ..., -4.140751 ,\n",
      "         -4.657219 , -5.1178355],\n",
      "        [13.465259 , -4.097384 , -4.4179034, ..., -4.151209 ,\n",
      "         -4.643125 , -5.101619 ]],\n",
      "\n",
      "       [[10.527641 , -3.2411811, -3.5474231, ..., -3.203087 ,\n",
      "         -4.1240087, -5.4090724],\n",
      "        [12.255399 , -3.2481868, -3.9800825, ..., -4.3268104,\n",
      "         -4.399975 , -5.4881363],\n",
      "        [12.489131 , -3.5077653, -2.9631546, ..., -3.8105638,\n",
      "         -4.5532346, -5.2542653],\n",
      "        ...,\n",
      "        [13.400847 , -3.7305331, -4.1903267, ..., -4.0007954,\n",
      "         -4.6963935, -5.4153113],\n",
      "        [13.391182 , -3.726018 , -4.188986 , ..., -4.0083184,\n",
      "         -4.6931624, -5.4093204],\n",
      "        [13.394914 , -3.7251866, -4.1796756, ..., -3.9906137,\n",
      "         -4.7131515, -5.4258523]]], dtype=float32), array([[  1.3510668,  -2.093196 ,  -6.227682 , ..., -10.037692 ,\n",
      "        -10.521099 ,  -9.284265 ],\n",
      "       [ -6.9154387,  -6.724922 ,  -8.537305 , ..., -15.176067 ,\n",
      "        -14.752896 , -14.109042 ],\n",
      "       [ -4.570983 ,  -6.6087685,  -3.3213701, ..., -10.563331 ,\n",
      "         -9.909536 ,  -8.56572  ],\n",
      "       ...,\n",
      "       [ -8.539383 ,  -7.15563  ,  -7.552422 , ..., -15.469097 ,\n",
      "        -14.777759 , -14.084039 ],\n",
      "       [ -4.0770936,  -6.7344694,  -3.8842864, ..., -10.432816 ,\n",
      "        -10.365968 ,  -9.091926 ],\n",
      "       [ -7.797839 ,  -6.611453 ,  -6.9742765, ..., -15.78601  ,\n",
      "        -15.158116 , -14.320247 ]], dtype=float32)]\n",
      "        -10.962064 , -10.418475 ]], dtype=float32)]\r"
     ]
    }
   ],
   "source": [
    "config = paddle.inference.Config(\"infer_model\" + \".pdmodel\",\n",
    "                                         \"infer_model\" + \".pdiparams\")\n",
    "config.disable_gpu()\n",
    "config.switch_use_feed_fetch_ops(False)\n",
    "\n",
    "predictor = paddle.inference.create_predictor(config)\n",
    "\n",
    "input_handles = [\n",
    "            predictor.get_input_handle(name)\n",
    "            for name in predictor.get_input_names()\n",
    "        ]\n",
    "output_handles = [\n",
    "            predictor.get_output_handle(name)\n",
    "            for name in predictor.get_output_names()\n",
    "        ]\n",
    "\n",
    "infer_batchify_fn = lambda samples, fn=Dict(\n",
    "        {\n",
    "            \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\n",
    "            \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id)\n",
    "        }): fn(samples)\n",
    "\n",
    "infer_data_loader = paddle.io.DataLoader(\n",
    "            dataset=dev_ds,\n",
    "            batch_sampler=dev_batch_sampler,\n",
    "            collate_fn=infer_batchify_fn,\n",
    "            num_workers=0,\n",
    "            return_list=True)\n",
    "\n",
    "for data in infer_data_loader:\n",
    "    for input_field, input_handle in zip(data, input_handles):\n",
    "        input_handle.copy_from_cpu(input_field.numpy() if isinstance(\n",
    "            input_field, paddle.Tensor) else input_field)\n",
    "    predictor.run()\n",
    "    output = [\n",
    "        output_handle.copy_to_cpu() for output_handle in output_handles\n",
    "    ]\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 引入对话历史\n",
    "\n",
    "在该数据集的原始论文中，提到了一种改进模型的手段。即将对话历史的特征传入模型。可以增强模型的表现。\n",
    "\n",
    "这里给大家举个例子：\n",
    "\n",
    "- **当前句**：\"好，玩累了周边有酒店可以休息吗？\"\n",
    "\n",
    "- **意图**：\"Request+景点+周边酒店\"\n",
    "\n",
    "- **历史**：[\"你好，帮我找一个20到50元之间的景点，谢谢。\",\"八达岭长城怎么样？门票35元。\"]\n",
    "\n",
    "在本示例中，可以通过修改数据处理函数的的`use_history`参数来控制是否使用这一策略。\n",
    "\n",
    "关于该策略的详细信息和原始baseline模型,请参考[CrossWOZ](https://github.com/thu-coai/CrossWOZ)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 更多任务\n",
    "\n",
    "关于更多任务型对话的示例和数据集，可以参考PaddleNLP中的[DGU](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/dialogue/dgu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以上内容实现基于PaddleNLP，开源不易，希望大家多多支持~ \n",
    "**记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐**\n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c54e958d7e50498381f2e89c84e2368723ff1db2f7c148518b1efa8890f93f0b)\n",
    "\n",
    "\n",
    "**更多使用方法可参考PaddleNLP教程**\n",
    "\n",
    "- [使用seq2vec模块进行句子情感分类](https://aistudio.baidu.com/aistudio/projectdetail/1283423)\n",
    "- [使用预训练模型ERNIE优化情感分析](https://aistudio.baidu.com/aistudio/projectdetail/1294333)\n",
    "- [使用BiGRU-CRF模型完成快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1317771)\n",
    "- [使用预训练模型ERNIE优化快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1329361)\n",
    "- [使用Seq2Seq模型完成自动对联](https://aistudio.baidu.com/aistudio/projectdetail/1321118)\n",
    "- [使用预训练模型ERNIE-GEN自动写诗](https://aistudio.baidu.com/aistudio/projectdetail/1339888)\n",
    "- [使用TCN网络完成新冠疫情病例数预测](https://aistudio.baidu.com/aistudio/projectdetail/1290873)\n",
    "- [自定义数据集实现文本多分类任务](https://aistudio.baidu.com/aistudio/projectdetail/1468469)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 加入交流群，一起学习吧\n",
    "\n",
    "现在就加入PaddleNLP的QQ技术交流群，一起交流NLP技术吧！\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/d953727af0c24a7c806ab529495f0904f22f809961be420b8c88cdf59b837394\" width=\"200\" height=\"250\" >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
